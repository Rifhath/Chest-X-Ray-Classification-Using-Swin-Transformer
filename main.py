# -*- coding: utf-8 -*-
"""Untitled37.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bpWsqXBDFwA3igQmASgMY-0bvwAbNIWd
"""

pip install transformers==4.18.0

pip install datasets==2.1.0

import transformers
import datasets
import tensorflow as tf
from PIL import Image
print("transformers version:", transformers.__version__)
print("datasets version:", datasets.__version__)

import os
os.listdir("/content/drive/MyDrive/chest_xray-2_aug")

from datasets import load_dataset
data_dir = "/content/drive/MyDrive/chest_xray-2_aug"

# load dataset
train_ds = load_dataset("imagefolder", data_dir=os.path.join(data_dir, "train"), split="train")
val_ds = load_dataset("imagefolder", data_dir=os.path.join(data_dir, "val"), split="train")
test_ds = load_dataset("imagefolder", data_dir=os.path.join(data_dir, "test"), split="train")

# label2idx and idx2label
id2label = {id:label for id, label in enumerate(train_ds.features['label'].names)}
label2id = {label:id for id,label in id2label.items()}
# split train, val, test

print("Features", train_ds.features)
print("Train", train_ds)
print("Validation", val_ds)
print("Test", test_ds)
print("Num labels", len(label2id))
print("Label2Idx", label2id)
print("Idx2Label", id2label)

from transformers import AutoFeatureExtractor
from torchvision.transforms import (
    CenterCrop, 
    Compose, 
    Normalize, 
    RandomHorizontalFlip,
    RandomResizedCrop, 
    Resize, 
    ToTensor
)

feature_extractor = AutoFeatureExtractor.from_pretrained("microsoft/swin-tiny-patch4-window7-224")

normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)
_train_transforms = Compose(
        [
            RandomResizedCrop(feature_extractor.size),
            RandomHorizontalFlip(),
            ToTensor(),
            normalize,
        ]
    )

_val_transforms = Compose(
        [
            Resize(feature_extractor.size),
            CenterCrop(feature_extractor.size),
            ToTensor(),
            normalize,
        ]
    )

def train_transforms(examples):
    examples['pixel_values'] = [_train_transforms(image.convert("RGB")) for image in examples['image']]
    return examples

def val_transforms(examples):
    examples['pixel_values'] = [_val_transforms(image.convert("RGB")) for image in examples['image']]
    return examples

# Set the transforms
train_ds.set_transform(train_transforms)
val_ds.set_transform(val_transforms)
test_ds.set_transform(val_transforms)

from torch.utils.data import DataLoader
import torch

def collate_fn(examples):
    pixel_values = torch.stack([example["pixel_values"] for example in examples])
    labels = torch.tensor([example["label"] for example in examples])
    return {"pixel_values": pixel_values, "labels": labels}

train_dataloader = DataLoader(train_ds, collate_fn=collate_fn, batch_size=4)

from transformers import SwinForImageClassification, SwinConfig

config = SwinConfig.from_pretrained(
        "microsoft/swin-tiny-patch4-window7-224",
        num_labels=len(label2id),
        label2id=label2id,
        id2label=id2label,
        finetuning_task="image-classification"
    )

model = SwinForImageClassification.from_pretrained(
    "microsoft/swin-tiny-patch4-window7-224",
    config=config,
    ignore_mismatched_sizes=True
)

from transformers import TrainingArguments, Trainer
metric_name = "accuracy"
args = TrainingArguments(
    f"chest_xray",
    save_strategy="epoch",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    num_train_epochs=5,
    weight_decay=0.01,
    load_best_model_at_end=True,
    save_total_limit=1,
    metric_for_best_model=metric_name,
    logging_dir='logs',
    remove_unused_columns=False,
)

from datasets import load_metric
import numpy as np

metric = load_metric(metric_name)

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)

trainer = Trainer(
    model,
    args,
    train_dataset=train_ds,
    eval_dataset=val_ds,
    data_collator=collate_fn,
    compute_metrics=compute_metrics,
    tokenizer=feature_extractor,
)

os.environ["WANDB_DISABLED"] = "true"
os.environ["WANDB_MODE"] = "offline"
train_results = trainer.train()
train_results

eval_results = trainer.evaluate()
eval_results

outputs = trainer.predict(test_ds)
print(outputs.metrics)
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_true = outputs.label_ids
y_pred = outputs.predictions.argmax(1)
labels = train_ds.features['label'].names

# Classification report
from sklearn.metrics import classification_report
print(classification_report(y_true, y_pred, target_names=labels))

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot()

import cv2
import matplotlib.pyplot as plt
from random import randint

list_idx = [randint(0, len(test_ds)) for i in range(25)]

def display_examples():
    fig = plt.figure(figsize=(12,12))
    fig.suptitle("Some examples of images of the test set", fontsize=18)
    for i,idx in enumerate(list_idx):
        plt.subplot(5,5,i+1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(test_ds[idx]["image"], cmap=plt.cm.binary)
        plt.xlabel("Label: "+id2label[y_true[idx]]+"\nPred: "+id2label[y_pred[idx]])
    plt.show()

display_examples()

# Load the Swin Transformer model
config = SwinConfig.from_pretrained("microsoft/swin-tiny-patch4-window7-224")
model = SwinForImageClassification.from_pretrained(
    "microsoft/swin-tiny-patch4-window7-224",
    config=config,
    ignore_mismatched_sizes=True
)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Generate some fake data for testing
x_train = np.random.rand(100, 224, 224, 3)
y_train = np.random.rand(100, 10)

# Fit the model
model.fit(x_train, y_train, epochs=10, batch_size=32)

# Save the model
model.save('swin_model.h5')

# Load the saved model
loaded_model = tf.keras.models.load_model('swin_model.h5')

# Load a random image
image = Image.open('/Users/rohitgangadhar/Downloads/chest_xray-2_aug/val/PNEUMONIA/enhanced_person1946_bacteria_4875.jpeg').resize((224, 224))

# Convert the image to a numpy array and normalize the pixel values
image_array = np.array(image) / 255.0

# Add an extra dimension to the array to create a batch of size 1
image_array = np.expand_dims(image_array, axis=0)

# Make a prediction using the loaded model
prediction = loaded_model.predict(image_array)

# Print the predicted class probabilities
print(prediction)
